{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"ag_optimized\"\n",
      "Verbosity: 3 (Detailed Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.10.0\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Tue Nov 5 00:21:55 UTC 2024\n",
      "CPU Count:          12\n",
      "GPU Count:          1\n",
      "Memory Avail:       54.69 GB / 57.48 GB (95.2%)\n",
      "Disk Space Avail:   3551.40 GB / 6519.49 GB (54.5%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "============ fit kwarg info ============\n",
      "User Specified kwargs:\n",
      "{'auto_stack': True, 'num_bag_sets': 1, 'verbosity': 3}\n",
      "Full kwargs:\n",
      "{'_feature_generator_kwargs': None,\n",
      " '_save_bag_folds': None,\n",
      " 'ag_args': None,\n",
      " 'ag_args_ensemble': None,\n",
      " 'ag_args_fit': None,\n",
      " 'auto_stack': True,\n",
      " 'calibrate': 'auto',\n",
      " 'delay_bag_sets': False,\n",
      " 'ds_args': {'clean_up_fits': True,\n",
      "             'detection_time_frac': 0.25,\n",
      "             'enable_callbacks': False,\n",
      "             'enable_ray_logging': True,\n",
      "             'holdout_data': None,\n",
      "             'holdout_frac': 0.1111111111111111,\n",
      "             'memory_safe_fits': True,\n",
      "             'n_folds': 2,\n",
      "             'n_repeats': 1,\n",
      "             'validation_procedure': 'holdout'},\n",
      " 'excluded_model_types': None,\n",
      " 'feature_generator': 'auto',\n",
      " 'feature_prune_kwargs': None,\n",
      " 'holdout_frac': None,\n",
      " 'hyperparameter_tune_kwargs': None,\n",
      " 'included_model_types': None,\n",
      " 'keep_only_best': False,\n",
      " 'learning_curves': False,\n",
      " 'name_suffix': None,\n",
      " 'num_bag_folds': None,\n",
      " 'num_bag_sets': 1,\n",
      " 'num_stack_levels': None,\n",
      " 'pseudo_data': None,\n",
      " 'raise_on_no_models_fitted': True,\n",
      " 'refit_full': False,\n",
      " 'save_bag_folds': None,\n",
      " 'save_space': False,\n",
      " 'set_best_to_refit_full': False,\n",
      " 'test_data': None,\n",
      " 'unlabeled_data': None,\n",
      " 'use_bag_holdout': False,\n",
      " 'verbosity': 3}\n",
      "========================================\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 1800s of the 7200s of remaining time (25%).\n",
      "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
      "2025-04-08 09:59:51,267\tINFO worker.py:1810 -- Started a local Ray instance. View the dashboard at \u001B[1m\u001B[32m127.0.0.1:8265 \u001B[39m\u001B[22m\n",
      "\t\tContext path: \"/mnt/n/code/competition/kaggle/Predict_Podcast_Listening_Time/notebook/ag_optimized/ds_sub_fit/sub_fit_ho\"\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m Running DyStack sub-fit ...\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m Saving /mnt/n/code/competition/kaggle/Predict_Podcast_Listening_Time/notebook/ag_optimized/ds_sub_fit/sub_fit_ho/learner.pkl\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m Saving /mnt/n/code/competition/kaggle/Predict_Podcast_Listening_Time/notebook/ag_optimized/ds_sub_fit/sub_fit_ho/predictor.pkl\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m Beginning AutoGluon training ... Time limit = 1787s\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m AutoGluon will save models to \"/mnt/n/code/competition/kaggle/Predict_Podcast_Listening_Time/notebook/ag_optimized/ds_sub_fit/sub_fit_ho\"\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m Train Data Rows:    666666\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m Train Data Columns: 13\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m Label Column:       Listening_Time_minutes\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m Problem Type:       regression\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m Preprocessing data ...\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m Using Feature Generators to preprocess the data ...\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m Fitting AutoMLPipelineFeatureGenerator...\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \tAvailable Memory:                    54380.72 MB\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \tTrain Data (Original)  Memory Usage: 66.12 MB (0.1% of available memory)\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \tStage 1 Generators:\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\tFitting AsTypeFeatureGenerator...\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\t\t\t('float64', 'float') : 4 | ['Episode_Length_minutes', 'Host_Popularity_percentage', 'Guest_Popularity_percentage', 'Number_of_Ads']\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\t\t\t('int64', 'int')     : 8 | ['Podcast_Name', 'Genre', 'Publication_Day', 'Episode_Sentiment', 'Time_Period', ...]\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\t\t\t('float', []) : 4 | ['Episode_Length_minutes', 'Host_Popularity_percentage', 'Guest_Popularity_percentage', 'Number_of_Ads']\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\t\t\t('int', [])   : 8 | ['Podcast_Name', 'Genre', 'Publication_Day', 'Episode_Sentiment', 'Time_Period', ...]\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\t\t\t('float', [])     : 4 | ['Episode_Length_minutes', 'Host_Popularity_percentage', 'Guest_Popularity_percentage', 'Number_of_Ads']\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\t\t\t('int', [])       : 7 | ['Podcast_Name', 'Genre', 'Publication_Day', 'Episode_Sentiment', 'Time_Period', ...]\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\t\t\t('int', ['bool']) : 1 | ['Is_Weekend']\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\t\t0.1s = Fit runtime\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\t\t12 features in original data used to generate 12 features in processed data.\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \tStage 2 Generators:\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\tFitting FillNaFeatureGenerator...\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\t\t\t('float', [])     : 4 | ['Episode_Length_minutes', 'Host_Popularity_percentage', 'Guest_Popularity_percentage', 'Number_of_Ads']\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\t\t\t('int', [])       : 7 | ['Podcast_Name', 'Genre', 'Publication_Day', 'Episode_Sentiment', 'Time_Period', ...]\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\t\t\t('int', ['bool']) : 1 | ['Is_Weekend']\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\t\t\t('float', [])     : 4 | ['Episode_Length_minutes', 'Host_Popularity_percentage', 'Guest_Popularity_percentage', 'Number_of_Ads']\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\t\t\t('int', [])       : 7 | ['Podcast_Name', 'Genre', 'Publication_Day', 'Episode_Sentiment', 'Time_Period', ...]\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\t\t\t('int', ['bool']) : 1 | ['Is_Weekend']\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\t\t0.1s = Fit runtime\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\t\t12 features in original data used to generate 12 features in processed data.\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \tStage 3 Generators:\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\tFitting IdentityFeatureGenerator...\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\t\t\t('float', [])     : 4 | ['Episode_Length_minutes', 'Host_Popularity_percentage', 'Guest_Popularity_percentage', 'Number_of_Ads']\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\t\t\t('int', [])       : 7 | ['Podcast_Name', 'Genre', 'Publication_Day', 'Episode_Sentiment', 'Time_Period', ...]\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\t\t\t('int', ['bool']) : 1 | ['Is_Weekend']\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\t\t\t('float', [])     : 4 | ['Episode_Length_minutes', 'Host_Popularity_percentage', 'Guest_Popularity_percentage', 'Number_of_Ads']\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\t\t\t('int', [])       : 7 | ['Podcast_Name', 'Genre', 'Publication_Day', 'Episode_Sentiment', 'Time_Period', ...]\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\t\t\t('int', ['bool']) : 1 | ['Is_Weekend']\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\t\t0.1s = Fit runtime\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\t\t12 features in original data used to generate 12 features in processed data.\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\tSkipping CategoryFeatureGenerator: No input feature with required dtypes.\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\tSkipping TextSpecialFeatureGenerator: No input feature with required dtypes.\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\tSkipping TextNgramFeatureGenerator: No input feature with required dtypes.\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \tStage 4 Generators:\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\tFitting DropUniqueFeatureGenerator...\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\t\t\t('float', [])     : 4 | ['Episode_Length_minutes', 'Host_Popularity_percentage', 'Guest_Popularity_percentage', 'Number_of_Ads']\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\t\t\t('int', [])       : 7 | ['Podcast_Name', 'Genre', 'Publication_Day', 'Episode_Sentiment', 'Time_Period', ...]\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\t\t\t('int', ['bool']) : 1 | ['Is_Weekend']\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\t\t\t('float', [])     : 4 | ['Episode_Length_minutes', 'Host_Popularity_percentage', 'Guest_Popularity_percentage', 'Number_of_Ads']\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\t\t\t('int', [])       : 7 | ['Podcast_Name', 'Genre', 'Publication_Day', 'Episode_Sentiment', 'Time_Period', ...]\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\t\t\t('int', ['bool']) : 1 | ['Is_Weekend']\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\t\t0.1s = Fit runtime\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\t\t12 features in original data used to generate 12 features in processed data.\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \tStage 5 Generators:\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\t\t\t('float', [])     : 4 | ['Episode_Length_minutes', 'Host_Popularity_percentage', 'Guest_Popularity_percentage', 'Number_of_Ads']\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\t\t\t('int', [])       : 7 | ['Podcast_Name', 'Genre', 'Publication_Day', 'Episode_Sentiment', 'Time_Period', ...]\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\t\t\t('int', ['bool']) : 1 | ['Is_Weekend']\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\t\t\t('float', [])     : 4 | ['Episode_Length_minutes', 'Host_Popularity_percentage', 'Guest_Popularity_percentage', 'Number_of_Ads']\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\t\t\t('int', [])       : 7 | ['Podcast_Name', 'Genre', 'Publication_Day', 'Episode_Sentiment', 'Time_Period', ...]\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\t\t\t('int', ['bool']) : 1 | ['Is_Weekend']\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\t\t0.1s = Fit runtime\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\t\t12 features in original data used to generate 12 features in processed data.\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \tUseless Original Features (Count: 1): ['Has_Special']\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\tThis is typically a feature which has the same value for all rows.\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\tThese features do not need to be present at inference time.\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \tTypes of features in original data (exact raw dtype, raw dtype):\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\t('float64', 'float') : 4 | ['Episode_Length_minutes', 'Host_Popularity_percentage', 'Guest_Popularity_percentage', 'Number_of_Ads']\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\t('int64', 'int')     : 8 | ['Podcast_Name', 'Genre', 'Publication_Day', 'Episode_Sentiment', 'Time_Period', ...]\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\t('float', []) : 4 | ['Episode_Length_minutes', 'Host_Popularity_percentage', 'Guest_Popularity_percentage', 'Number_of_Ads']\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\t('int', [])   : 8 | ['Podcast_Name', 'Genre', 'Publication_Day', 'Episode_Sentiment', 'Time_Period', ...]\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\t('float64', 'float') : 4 | ['Episode_Length_minutes', 'Host_Popularity_percentage', 'Guest_Popularity_percentage', 'Number_of_Ads']\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\t('int64', 'int')     : 7 | ['Podcast_Name', 'Genre', 'Publication_Day', 'Episode_Sentiment', 'Time_Period', ...]\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\t('int8', 'int')      : 1 | ['Is_Weekend']\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\t('float', [])     : 4 | ['Episode_Length_minutes', 'Host_Popularity_percentage', 'Guest_Popularity_percentage', 'Number_of_Ads']\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\t('int', [])       : 7 | ['Podcast_Name', 'Genre', 'Publication_Day', 'Episode_Sentiment', 'Time_Period', ...]\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t\t('int', ['bool']) : 1 | ['Is_Weekend']\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t0.7s = Fit runtime\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t12 features in original data used to generate 12 features in processed data.\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \tTrain Data (Processed) Memory Usage: 56.58 MB (0.1% of available memory)\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m Data preprocessing and feature engineering runtime = 0.83s ...\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m Saving /mnt/n/code/competition/kaggle/Predict_Podcast_Listening_Time/notebook/ag_optimized/ds_sub_fit/sub_fit_ho/learner.pkl\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m User-specified model hyperparameters to be fit:\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m {\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t'GBM': [{'num_boost_round': 300}],\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t'CAT': [{'iterations': 1500}],\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t'XGB': [{'max_depth': 10}],\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m }\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m Saving /mnt/n/code/competition/kaggle/Predict_Podcast_Listening_Time/notebook/ag_optimized/ds_sub_fit/sub_fit_ho/utils/data/X.pkl\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m Saving /mnt/n/code/competition/kaggle/Predict_Podcast_Listening_Time/notebook/ag_optimized/ds_sub_fit/sub_fit_ho/utils/data/y.pkl\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m Model configs that will be trained (in order):\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \tLightGBM_BAG_L1: \t{'num_boost_round': 300, 'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \tCatBoost_BAG_L1: \t{'iterations': 1500, 'ag_args': {'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}}\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \tXGBoost_BAG_L1: \t{'max_depth': 10, 'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m Fitting 3 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 1190.52s of the 1786.22s of remaining time.\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \tFitting LightGBM_BAG_L1 with 'num_gpus': 0, 'num_cpus': 12\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m Saving /mnt/n/code/competition/kaggle/Predict_Podcast_Listening_Time/notebook/ag_optimized/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m Loading: /mnt/n/code/competition/kaggle/Predict_Podcast_Listening_Time/notebook/ag_optimized/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.73%)\n",
      "\u001B[36m(_ray_fit pid=51079)\u001B[0m \tFitting 300 rounds... Hyperparameters: {'learning_rate': 0.05}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(_ray_fit pid=51079)\u001B[0m [50]\tvalid_set's rmse: 13.3009\n",
      "\u001B[36m(_ray_fit pid=51078)\u001B[0m [100]\tvalid_set's rmse: 13.1496\u001B[32m [repeated 11x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001B[0m\n",
      "\u001B[36m(_ray_fit pid=51085)\u001B[0m [200]\tvalid_set's rmse: 13.1019\u001B[32m [repeated 16x across cluster]\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[36m(_ray_fit pid=51084)\u001B[0m Saving /mnt/n/code/competition/kaggle/Predict_Podcast_Listening_Time/notebook/ag_optimized/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/S1F8/model.pkl\n",
      "\u001B[36m(_ray_fit pid=51084)\u001B[0m \tFitting 300 rounds... Hyperparameters: {'learning_rate': 0.05}\u001B[32m [repeated 7x across cluster]\u001B[0m\n",
      "\u001B[36m(_ray_fit pid=51079)\u001B[0m Saving /mnt/n/code/competition/kaggle/Predict_Podcast_Listening_Time/notebook/ag_optimized/ds_sub_fit/sub_fit_ho/models/LightGBM_BAG_L1/S1F3/model.pkl\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t-13.0779\t = Validation score   (-root_mean_squared_error)\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t21.35s\t = Training   runtime\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t10.45s\t = Validation runtime\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \t7971.1\t = Inference  throughput (rows/s | 83334 batch size)\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m Saving /mnt/n/code/competition/kaggle/Predict_Podcast_Listening_Time/notebook/ag_optimized/ds_sub_fit/sub_fit_ho/models/trainer.pkl\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m Fitting model: CatBoost_BAG_L1 ... Training model for up to 1165.44s of the 1761.15s of remaining time.\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \tFitting CatBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 12\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m Loading: /mnt/n/code/competition/kaggle/Predict_Podcast_Listening_Time/notebook/ag_optimized/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=0.75%)\n",
      "\u001B[36m(_ray_fit pid=51539)\u001B[0m \tCatboost model hyperparameters: {'iterations': 1500, 'learning_rate': 0.05, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'RMSE', 'thread_count': 1}\n",
      "\u001B[36m(_dystack pid=50271)\u001B[0m Saving /mnt/n/code/competition/kaggle/Predict_Podcast_Listening_Time/notebook/ag_optimized/ds_sub_fit/sub_fit_ho/models/CatBoost_BAG_L1/utils/model_template.pkl\u001B[32m [repeated 9x across cluster]\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m(_ray_fit pid=51539)\u001B[0m 0:\tlearn: 26.1731009\ttest: 26.1177815\tbest: 26.1177815 (0)\ttotal: 244ms\tremaining: 6m 5s\n",
      "\u001B[36m(_ray_fit pid=51081)\u001B[0m [300]\tvalid_set's rmse: 13.1391\u001B[32m [repeated 20x across cluster]\u001B[0m\n",
      "\u001B[36m(_ray_fit pid=51544)\u001B[0m 40:\tlearn: 13.6857033\ttest: 13.7775108\tbest: 13.7775108 (40)\ttotal: 7.22s\tremaining: 4m 17s\u001B[32m [repeated 16x across cluster]\u001B[0m\n",
      "\u001B[36m(_ray_fit pid=51542)\u001B[0m 80:\tlearn: 13.2301134\ttest: 13.2159761\tbest: 13.2159761 (80)\ttotal: 14.4s\tremaining: 4m 13s\u001B[32m [repeated 16x across cluster]\u001B[0m\n",
      "\u001B[36m(_ray_fit pid=51544)\u001B[0m 120:\tlearn: 13.1727460\ttest: 13.2537050\tbest: 13.2537050 (120)\ttotal: 21.3s\tremaining: 4m 2s\u001B[32m [repeated 16x across cluster]\u001B[0m\n",
      "\u001B[36m(_ray_fit pid=51544)\u001B[0m 160:\tlearn: 13.1529136\ttest: 13.2355149\tbest: 13.2355149 (160)\ttotal: 27.9s\tremaining: 3m 51s\u001B[32m [repeated 16x across cluster]\u001B[0m\n",
      "\u001B[36m(_ray_fit pid=51538)\u001B[0m 180:\tlearn: 13.1637128\ttest: 13.1100385\tbest: 13.1100385 (180)\ttotal: 33.2s\tremaining: 4m 1s\u001B[32m [repeated 14x across cluster]\u001B[0m\n",
      "\u001B[36m(_ray_fit pid=51539)\u001B[0m 220:\tlearn: 13.1438666\ttest: 13.1640268\tbest: 13.1640268 (220)\ttotal: 38.3s\tremaining: 3m 41s\u001B[32m [repeated 13x across cluster]\u001B[0m\n",
      "\u001B[36m(_ray_fit pid=51540)\u001B[0m 240:\tlearn: 13.1381833\ttest: 13.1541204\tbest: 13.1541204 (240)\ttotal: 43.4s\tremaining: 3m 46s\u001B[32m [repeated 12x across cluster]\u001B[0m\n",
      "\u001B[36m(_ray_fit pid=51539)\u001B[0m 280:\tlearn: 13.1280697\ttest: 13.1539243\tbest: 13.1539243 (280)\ttotal: 48.7s\tremaining: 3m 31s\u001B[32m [repeated 12x across cluster]\u001B[0m\n",
      "\u001B[36m(_ray_fit pid=51537)\u001B[0m 300:\tlearn: 13.1227317\ttest: 13.1558285\tbest: 13.1558285 (300)\ttotal: 53.7s\tremaining: 3m 33s\u001B[32m [repeated 10x across cluster]\u001B[0m\n",
      "\u001B[36m(_ray_fit pid=51544)\u001B[0m 340:\tlearn: 13.1009944\ttest: 13.1939186\tbest: 13.1939186 (340)\ttotal: 58.7s\tremaining: 3m 19s\u001B[32m [repeated 9x across cluster]\u001B[0m\n",
      "\u001B[36m(_ray_fit pid=51537)\u001B[0m 360:\tlearn: 13.1056908\ttest: 13.1454596\tbest: 13.1454596 (360)\ttotal: 1m 3s\tremaining: 3m 21s\u001B[32m [repeated 15x across cluster]\u001B[0m\n",
      "\u001B[36m(_ray_fit pid=51543)\u001B[0m 400:\tlearn: 13.0944266\ttest: 13.1451266\tbest: 13.1451266 (400)\ttotal: 1m 8s\tremaining: 3m 8s\u001B[32m [repeated 11x across cluster]\u001B[0m\n",
      "\u001B[36m(_ray_fit pid=51544)\u001B[0m 440:\tlearn: 13.0776958\ttest: 13.1783428\tbest: 13.1783428 (440)\ttotal: 1m 14s\tremaining: 2m 59s\u001B[32m [repeated 14x across cluster]\u001B[0m\n",
      "\u001B[36m(_ray_fit pid=51540)\u001B[0m 440:\tlearn: 13.0890750\ttest: 13.1171068\tbest: 13.1171068 (440)\ttotal: 1m 19s\tremaining: 3m 11s\u001B[32m [repeated 14x across cluster]\u001B[0m\n",
      "\u001B[36m(_ray_fit pid=51543)\u001B[0m 500:\tlearn: 13.0724145\ttest: 13.1331303\tbest: 13.1331303 (500)\ttotal: 1m 25s\tremaining: 2m 50s\u001B[32m [repeated 12x across cluster]\u001B[0m\n",
      "\u001B[36m(_ray_fit pid=51537)\u001B[0m 520:\tlearn: 13.0720056\ttest: 13.1271226\tbest: 13.1271226 (520)\ttotal: 1m 30s\tremaining: 2m 49s\u001B[32m [repeated 12x across cluster]\u001B[0m\n",
      "\u001B[36m(_ray_fit pid=51543)\u001B[0m 560:\tlearn: 13.0607806\ttest: 13.1272039\tbest: 13.1272039 (560)\ttotal: 1m 35s\tremaining: 2m 39s\u001B[32m [repeated 12x across cluster]\u001B[0m\n",
      "\u001B[36m(_ray_fit pid=51537)\u001B[0m 580:\tlearn: 13.0607001\ttest: 13.1210798\tbest: 13.1210798 (580)\ttotal: 1m 42s\tremaining: 2m 41s\u001B[32m [repeated 11x across cluster]\u001B[0m\n",
      "\u001B[36m(_ray_fit pid=51539)\u001B[0m 620:\tlearn: 13.0517604\ttest: 13.1144844\tbest: 13.1144844 (620)\ttotal: 1m 47s\tremaining: 2m 32s\u001B[32m [repeated 12x across cluster]\u001B[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 42\u001B[0m\n\u001B[1;32m     39\u001B[0m test \u001B[38;5;241m=\u001B[39m add_features(test)\n\u001B[1;32m     41\u001B[0m \u001B[38;5;66;03m# 模型训练配置优化\u001B[39;00m\n\u001B[0;32m---> 42\u001B[0m predictor \u001B[38;5;241m=\u001B[39m \u001B[43mTabularPredictor\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     43\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlabel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mListening_Time_minutes\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     44\u001B[0m \u001B[43m    \u001B[49m\u001B[43mproblem_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mregression\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     45\u001B[0m \u001B[43m    \u001B[49m\u001B[43meval_metric\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mroot_mean_squared_error\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     46\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mag_optimized\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\n\u001B[1;32m     47\u001B[0m \u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     48\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     49\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpresets\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mbest_quality\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     50\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtime_limit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m7200\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# 延长至2小时\u001B[39;49;00m\n\u001B[1;32m     51\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhyperparameters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\n\u001B[1;32m     52\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mGBM\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mnum_boost_round\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m300\u001B[39;49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     53\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mCAT\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43miterations\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1500\u001B[39;49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     54\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mXGB\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmax_depth\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m}\u001B[49m\n\u001B[1;32m     55\u001B[0m \u001B[43m    \u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     56\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbosity\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m3\u001B[39;49m\n\u001B[1;32m     57\u001B[0m \u001B[43m)\u001B[49m\n\u001B[1;32m     59\u001B[0m \u001B[38;5;66;03m# 生成预测结果\u001B[39;00m\n\u001B[1;32m     60\u001B[0m test_pred \u001B[38;5;241m=\u001B[39m predictor\u001B[38;5;241m.\u001B[39mpredict(test)\n",
      "File \u001B[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/autogluon/core/utils/decorators.py:31\u001B[0m, in \u001B[0;36munpack.<locals>._unpack_inner.<locals>._call\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     28\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(f)\n\u001B[1;32m     29\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_call\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     30\u001B[0m     gargs, gkwargs \u001B[38;5;241m=\u001B[39m g(\u001B[38;5;241m*\u001B[39mother_args, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m---> 31\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mgargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mgkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/autogluon/tabular/predictor/predictor.py:1280\u001B[0m, in \u001B[0;36mTabularPredictor.fit\u001B[0;34m(self, train_data, tuning_data, time_limit, presets, hyperparameters, feature_metadata, infer_limit, infer_limit_batch_size, fit_weighted_ensemble, fit_full_last_level_weighted_ensemble, full_weighted_ensemble_additionally, dynamic_stacking, calibrate_decision_threshold, num_cpus, num_gpus, fit_strategy, memory_limit, callbacks, **kwargs)\u001B[0m\n\u001B[1;32m   1274\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m dynamic_stacking:\n\u001B[1;32m   1275\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog(\n\u001B[1;32m   1276\u001B[0m         \u001B[38;5;241m20\u001B[39m,\n\u001B[1;32m   1277\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDyStack is enabled (dynamic_stacking=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdynamic_stacking\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m). \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1278\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1279\u001B[0m     )\n\u001B[0;32m-> 1280\u001B[0m     num_stack_levels, time_limit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dynamic_stacking\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mds_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mag_fit_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mag_fit_kwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mag_post_fit_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mag_post_fit_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1281\u001B[0m     logger\u001B[38;5;241m.\u001B[39minfo(\n\u001B[1;32m   1282\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mStarting main fit with num_stack_levels=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_stack_levels\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1283\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;124mFor future fit calls on this dataset, you can skip DyStack to save time: \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1284\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`predictor.fit(..., dynamic_stacking=False, num_stack_levels=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_stack_levels\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m)`\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1285\u001B[0m     )\n\u001B[1;32m   1287\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m (time_limit \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;129;01mand\u001B[39;00m (time_limit \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m):\n",
      "File \u001B[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/autogluon/tabular/predictor/predictor.py:1380\u001B[0m, in \u001B[0;36mTabularPredictor._dynamic_stacking\u001B[0;34m(self, ag_fit_kwargs, ag_post_fit_kwargs, validation_procedure, detection_time_frac, holdout_frac, n_folds, n_repeats, memory_safe_fits, clean_up_fits, enable_ray_logging, enable_callbacks, holdout_data)\u001B[0m\n\u001B[1;32m   1377\u001B[0m         _, holdout_data, _, _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_fit_data(train_data\u001B[38;5;241m=\u001B[39mX, tuning_data\u001B[38;5;241m=\u001B[39mholdout_data)\n\u001B[1;32m   1378\u001B[0m         ds_fit_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mds_fit_context\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(ds_fit_context, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msub_fit_custom_ho\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m-> 1380\u001B[0m     stacked_overfitting \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sub_fit_memory_save_wrapper\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1381\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1382\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtime_limit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtime_limit\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1383\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtime_start\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtime_start\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1384\u001B[0m \u001B[43m        \u001B[49m\u001B[43mds_fit_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mds_fit_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1385\u001B[0m \u001B[43m        \u001B[49m\u001B[43mag_fit_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minner_ag_fit_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1386\u001B[0m \u001B[43m        \u001B[49m\u001B[43mag_post_fit_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minner_ag_post_fit_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1387\u001B[0m \u001B[43m        \u001B[49m\u001B[43mholdout_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mholdout_data\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1388\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1389\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1390\u001B[0m     \u001B[38;5;66;03m# Holdout is false, use (repeated) cross-validation\u001B[39;00m\n\u001B[1;32m   1391\u001B[0m     is_stratified \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mproblem_type \u001B[38;5;129;01min\u001B[39;00m [REGRESSION, QUANTILE, SOFTCLASS]\n",
      "File \u001B[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/autogluon/tabular/predictor/predictor.py:1563\u001B[0m, in \u001B[0;36mTabularPredictor._sub_fit_memory_save_wrapper\u001B[0;34m(self, train_data, time_limit, time_start, ds_fit_kwargs, ag_fit_kwargs, ag_post_fit_kwargs, holdout_data)\u001B[0m\n\u001B[1;32m   1549\u001B[0m \u001B[38;5;66;03m# FIXME: For some reason ray does not treat `num_cpus` and `num_gpus` the same.\u001B[39;00m\n\u001B[1;32m   1550\u001B[0m \u001B[38;5;66;03m#  For `num_gpus`, the process will reserve the capacity and is unable to share it to child ray processes, causing a deadlock.\u001B[39;00m\n\u001B[1;32m   1551\u001B[0m \u001B[38;5;66;03m#  For `num_cpus`, the value is completely ignored by children, and they can even use more num_cpus than the parent.\u001B[39;00m\n\u001B[1;32m   1552\u001B[0m \u001B[38;5;66;03m#  Because of this, num_gpus is set to 0 here to avoid a deadlock, but num_cpus does not need to be changed.\u001B[39;00m\n\u001B[1;32m   1553\u001B[0m \u001B[38;5;66;03m#  For more info, refer to Ray documentation: https://docs.ray.io/en/latest/ray-core/tasks/nested-tasks.html#yielding-resources-while-blocked\u001B[39;00m\n\u001B[1;32m   1554\u001B[0m ref \u001B[38;5;241m=\u001B[39m sub_fit_caller\u001B[38;5;241m.\u001B[39moptions(num_cpus\u001B[38;5;241m=\u001B[39mnum_cpus, num_gpus\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\u001B[38;5;241m.\u001B[39mremote(\n\u001B[1;32m   1555\u001B[0m     predictor\u001B[38;5;241m=\u001B[39mpredictor_ref,\n\u001B[1;32m   1556\u001B[0m     train_data\u001B[38;5;241m=\u001B[39mtrain_data_ref,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1561\u001B[0m     holdout_data\u001B[38;5;241m=\u001B[39mholdout_data_ref,\n\u001B[1;32m   1562\u001B[0m )\n\u001B[0;32m-> 1563\u001B[0m finished, unfinished \u001B[38;5;241m=\u001B[39m \u001B[43m_ds_ray\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mref\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_returns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1564\u001B[0m stacked_overfitting, ho_leaderboard, exception \u001B[38;5;241m=\u001B[39m _ds_ray\u001B[38;5;241m.\u001B[39mget(finished[\u001B[38;5;241m0\u001B[39m])\n\u001B[1;32m   1566\u001B[0m \u001B[38;5;66;03m# TODO: This is present to ensure worker logs are properly logged and don't get skipped / printed out of order.\u001B[39;00m\n\u001B[1;32m   1567\u001B[0m \u001B[38;5;66;03m#  Ideally find a faster way to do this that doesn't introduce a 100 ms overhead.\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/ray/_private/auto_init_hook.py:21\u001B[0m, in \u001B[0;36mwrap_auto_init.<locals>.auto_init_wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(fn)\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mauto_init_wrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     20\u001B[0m     auto_init_ray()\n\u001B[0;32m---> 21\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/ray/_private/client_mode_hook.py:103\u001B[0m, in \u001B[0;36mclient_mode_hook.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    101\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m func\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minit\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m is_client_mode_enabled_by_default:\n\u001B[1;32m    102\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(ray, func\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m)(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m--> 103\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/py310/lib/python3.10/site-packages/ray/_private/worker.py:2984\u001B[0m, in \u001B[0;36mwait\u001B[0;34m(ray_waitables, num_returns, timeout, fetch_local)\u001B[0m\n\u001B[1;32m   2982\u001B[0m timeout \u001B[38;5;241m=\u001B[39m timeout \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m10\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m6\u001B[39m\n\u001B[1;32m   2983\u001B[0m timeout_milliseconds \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(timeout \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m1000\u001B[39m)\n\u001B[0;32m-> 2984\u001B[0m ready_ids, remaining_ids \u001B[38;5;241m=\u001B[39m \u001B[43mworker\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcore_worker\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2985\u001B[0m \u001B[43m    \u001B[49m\u001B[43mray_waitables\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2986\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_returns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2987\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout_milliseconds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2988\u001B[0m \u001B[43m    \u001B[49m\u001B[43mworker\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcurrent_task_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2989\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfetch_local\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2990\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2991\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m ready_ids, remaining_ids\n",
      "File \u001B[0;32mpython/ray/_raylet.pyx:3816\u001B[0m, in \u001B[0;36mray._raylet.CoreWorker.wait\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpython/ray/includes/common.pxi:79\u001B[0m, in \u001B[0;36mray._raylet.check_status\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import autogluon\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def add_features(df):\n",
    "    # 时间分类特征处理\n",
    "    time_map = {\"Morning\":0, \"Afternoon\":1, \"Evening\":2, \"Night\":3}\n",
    "    df['Time_Period'] = df['Publication_Time'].map(time_map)\n",
    "\n",
    "    # 日期特征\n",
    "    day_map = {'Monday':0, 'Tuesday':1, 'Wednesday':2, 'Thursday':3,\n",
    "             'Friday':4, 'Saturday':5, 'Sunday':6}\n",
    "    df['Publication_Day'] = df['Publication_Day'].map(day_map)\n",
    "\n",
    "    # 新增交互特征\n",
    "    df['Is_Weekend'] = (df['Publication_Day'] >= 5).astype(int)\n",
    "    df['Genre_Time'] = df['Genre'] + '_' + df['Time_Period'].astype(str)\n",
    "\n",
    "    # 文本特征处理\n",
    "    df['Title_Length'] = df['Episode_Title'].str.len()\n",
    "    df['Has_Special'] = df['Episode_Title'].str.contains('特别版|直播|专访').astype(int)\n",
    "\n",
    "    # 分类特征编码\n",
    "    cat_features = ['Podcast_Name', 'Genre', 'Episode_Sentiment', 'Genre_Time']\n",
    "    for col in cat_features:\n",
    "        if col in df.columns:\n",
    "            le = LabelEncoder()\n",
    "            df[col] = le.fit_transform(df[col].astype(str))\n",
    "\n",
    "    # 删除冗余列\n",
    "    return df.drop(columns=['Publication_Time', 'Episode_Title'], errors='ignore')\n",
    "\n",
    "# 数据加载与处理\n",
    "train = pd.read_csv(\"../data/playground-series-s5e4/train.csv\", index_col='id')\n",
    "test = pd.read_csv('../data/playground-series-s5e4/test.csv', index_col='id')\n",
    "train = add_features(train)\n",
    "test = add_features(test)\n",
    "\n",
    "# 模型训练配置优化\n",
    "predictor = TabularPredictor(\n",
    "    label='Listening_Time_minutes',\n",
    "    problem_type='regression',\n",
    "    eval_metric='root_mean_squared_error',\n",
    "    path='ag_optimized'\n",
    ").fit(\n",
    "    train_data=train,\n",
    "    presets='best_quality',\n",
    "    time_limit=7200,  # 延长至2小时\n",
    "    hyperparameters={\n",
    "        'GBM': {'num_boost_round': 300},\n",
    "        'CAT': {'iterations': 1500},\n",
    "        'XGB': {'max_depth': 10}\n",
    "    },\n",
    "    verbosity=3\n",
    ")\n",
    "\n",
    "# 生成预测结果\n",
    "test_pred = predictor.predict(test)\n",
    "submission = pd.DataFrame({'id': test.index, 'Listening_Time_minutes': test_pred})\n",
    "submission.to_csv('../output/submission_final.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
